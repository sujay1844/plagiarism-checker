{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-21 07:11:06.109792: W tensorflow/tsl/framework/cpu_allocator_impl.cc:83] Allocation of 93763584 exceeds 10% of free system memory.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text1</th>\n",
       "      <th>text2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>The kids are frowning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
       "      <td>The boy skates down the sidewalk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               text1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2              Children smiling and waving at camera   \n",
       "3              Children smiling and waving at camera   \n",
       "4  A boy is jumping on skateboard in the middle o...   \n",
       "\n",
       "                                           text2  label  \n",
       "0  A person is at a diner, ordering an omelette.      0  \n",
       "1              A person is outdoors, on a horse.      1  \n",
       "2                     There are children present      1  \n",
       "3                          The kids are frowning      0  \n",
       "4              The boy skates down the sidewalk.      0  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Load the BERT model\n",
    "module_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/3\"\n",
    "bert_layer = hub.KerasLayer(module_url, trainable=True)\n",
    "\n",
    "# Load the data into a Pandas DataFrame\n",
    "data = pd.read_csv(\"./train_snli.txt.zip\", sep=\"\\t\", header=None, names=[\"text1\", \"text2\", \"label\"])\n",
    "data['text1'] = data['text1'].astype(str)\n",
    "data['text2'] = data['text2'].astype(str)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer \"keras_layer_3\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/sujay1844/.local/share/virtualenvs/plagiarism-checker-C_ALrIvo/lib64/python3.11/site-packages/tensorflow_hub/keras_layer.py\", line 242, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>,\n     <tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>,\n     <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_3\" (type KerasLayer):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)']\n  • training=None",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 15\u001b[0m\n\u001b[1;32m     12\u001b[0m segment_ids \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mInput(shape\u001b[39m=\u001b[39m(max_seq_length,), dtype\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mint32, name\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39msegment_ids\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[39m# Connect the BERT layer\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m pooled_output, sequence_output \u001b[39m=\u001b[39m bert_layer([input_word_ids, input_mask, segment_ids])\n\u001b[1;32m     17\u001b[0m \u001b[39m# Add additional layers on top of BERT\u001b[39;00m\n\u001b[1;32m     18\u001b[0m x \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39mlayers\u001b[39m.\u001b[39mDense(\u001b[39m64\u001b[39m, activation\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mrelu\u001b[39m\u001b[39m\"\u001b[39m)(pooled_output)\n",
      "File \u001b[0;32m~/.local/share/virtualenvs/plagiarism-checker-C_ALrIvo/lib64/python3.11/site-packages/keras/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuz6patau.py:74\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call\u001b[0;34m(self, inputs, training)\u001b[0m\n\u001b[1;32m     72\u001b[0m     result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m), fscope))), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     73\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mUndefined(\u001b[39m'\u001b[39m\u001b[39mresult\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m---> 74\u001b[0m ag__\u001b[39m.\u001b[39;49mif_stmt(ag__\u001b[39m.\u001b[39;49mnot_(ag__\u001b[39m.\u001b[39;49mld(\u001b[39mself\u001b[39;49m)\u001b[39m.\u001b[39;49m_has_training_argument), if_body_3, else_body_3, get_state_3, set_state_3, (\u001b[39m'\u001b[39;49m\u001b[39mresult\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mtraining\u001b[39;49m\u001b[39m'\u001b[39;49m), \u001b[39m1\u001b[39;49m)\n\u001b[1;32m     76\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mget_state_6\u001b[39m():\n\u001b[1;32m     77\u001b[0m     \u001b[39mreturn\u001b[39;00m (result,)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuz6patau.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(smart_cond)\u001b[39m.\u001b[39;49msmart_cond, (ag__\u001b[39m.\u001b[39;49mld(training), ag__\u001b[39m.\u001b[39;49mautograph_artifact(\u001b[39mlambda\u001b[39;49;00m: ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m), fscope)), ag__\u001b[39m.\u001b[39;49mautograph_artifact(\u001b[39mlambda\u001b[39;49;00m: ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope))), \u001b[39mNone\u001b[39;49;00m, fscope)\n",
      "File \u001b[0;32m/tmp/__autograph_generated_fileuz6patau.py:72\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__call.<locals>.else_body_3.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m     training \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[1;32m     71\u001b[0m ag__\u001b[39m.\u001b[39mif_stmt(ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m)\u001b[39m.\u001b[39mtrainable, if_body_2, else_body_2, get_state_2, set_state_2, (\u001b[39m'\u001b[39m\u001b[39mtraining\u001b[39m\u001b[39m'\u001b[39m,), \u001b[39m1\u001b[39m)\n\u001b[0;32m---> 72\u001b[0m result \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(smart_cond)\u001b[39m.\u001b[39msmart_cond, (ag__\u001b[39m.\u001b[39mld(training), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(f), (), \u001b[39mdict\u001b[39m(training\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m), fscope)), ag__\u001b[39m.\u001b[39mautograph_artifact(\u001b[39mlambda\u001b[39;00m: ag__\u001b[39m.\u001b[39;49mconverted_call(ag__\u001b[39m.\u001b[39;49mld(f), (), \u001b[39mdict\u001b[39;49m(training\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m), fscope))), \u001b[39mNone\u001b[39;00m, fscope)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer \"keras_layer_3\" (type KerasLayer).\n\nin user code:\n\n    File \"/home/sujay1844/.local/share/virtualenvs/plagiarism-checker-C_ALrIvo/lib64/python3.11/site-packages/tensorflow_hub/keras_layer.py\", line 242, in call  *\n        result = smart_cond.smart_cond(training,\n\n    ValueError: Could not find matching concrete function to call loaded from the SavedModel. Got:\n      Positional arguments (3 total):\n        * [<tf.Tensor 'inputs:0' shape=(None, 128) dtype=int32>,\n     <tf.Tensor 'inputs_1:0' shape=(None, 128) dtype=int32>,\n     <tf.Tensor 'inputs_2:0' shape=(None, 128) dtype=int32>]\n        * False\n        * None\n      Keyword arguments: {}\n    \n     Expected these arguments to match one of the following 4 option(s):\n    \n    Option 1:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 2:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n    \n    Option 3:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='input_word_ids')}\n        * False\n        * None\n      Keyword arguments: {}\n    \n    Option 4:\n      Positional arguments (3 total):\n        * {'input_mask': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_mask'),\n     'input_type_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_type_ids'),\n     'input_word_ids': TensorSpec(shape=(None, None), dtype=tf.int32, name='inputs/input_word_ids')}\n        * True\n        * None\n      Keyword arguments: {}\n\n\nCall arguments received by layer \"keras_layer_3\" (type KerasLayer):\n  • inputs=['tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)', 'tf.Tensor(shape=(None, 128), dtype=int32)']\n  • training=None"
     ]
    }
   ],
   "source": [
    "\n",
    "# Split the data into training and validation sets\n",
    "train, val = train_test_split(data, test_size=0.2)\n",
    "\n",
    "# Define the tokenizer\n",
    "tokenizer = tf.keras.preprocessing.text.Tokenizer()\n",
    "tokenizer.fit_on_texts(train[\"text1\"].values + train[\"text2\"].values)\n",
    "\n",
    "# Define the input layers\n",
    "max_seq_length = 128\n",
    "input_word_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_word_ids\")\n",
    "input_mask = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"input_mask\")\n",
    "segment_ids = tf.keras.layers.Input(shape=(max_seq_length,), dtype=tf.int32, name=\"segment_ids\")\n",
    "\n",
    "# Connect the BERT layer\n",
    "pooled_output, sequence_output = bert_layer([input_word_ids, input_mask, segment_ids])\n",
    "\n",
    "# Add additional layers on top of BERT\n",
    "x = tf.keras.layers.Dense(64, activation=\"relu\")(pooled_output)\n",
    "output = tf.keras.layers.Dense(1, activation=\"sigmoid\")(x)\n",
    "\n",
    "# Define the model input and output\n",
    "model = tf.keras.models.Model(\n",
    "    inputs=[input_word_ids, input_mask, segment_ids], outputs=output\n",
    ")\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "    loss=\"binary_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "\n",
    "# Convert the text data to input features for BERT\n",
    "def convert_example_to_feature(text1, text2, max_seq_length):\n",
    "    tokens_a = tokenizer.tokenize(text1)\n",
    "    tokens_b = tokenizer.tokenize(text2)\n",
    "\n",
    "    # Combine the two texts and add [CLS] and [SEP] tokens\n",
    "    tokens = [\"[CLS]\"] + tokens_a + [\"[SEP]\"] + tokens_b + [\"[SEP]\"]\n",
    "\n",
    "    # Truncate or pad the sequence to the maximum sequence length\n",
    "    if len(tokens) > max_seq_length:\n",
    "        tokens = tokens[:max_seq_length]\n",
    "    else:\n",
    "        tokens += [\"[PAD]\"] * (max_seq_length - len(tokens))\n",
    "\n",
    "    # Convert tokens to input IDs, input masks, and segment IDs\n",
    "    input_ids = tokenizer.convert_tokens_to_ids(tokens)\n",
    "    input_masks = [1] * len(input_ids)\n",
    "    segment_ids = [0] * (len(tokens_a) + 2) + [1] * (len(tokens_b) + 1)\n",
    "\n",
    "    return input_ids, input_masks, segment_ids\n",
    "\n",
    "# Define a function to create the input features for BERT\n",
    "def create_input_features(df, max_seq_length):\n",
    "    input_ids, input_masks, segment_ids = [], [], []\n",
    "    for _, row in df.iterrows():\n",
    "        text1, text2 = row[\"text1\"], row[\"text2\"]\n",
    "        input_id, input_mask, segment_id = convert_example_to_feature(text1, text2, max_seq_length)\n",
    "        input_ids.append(input_id)\n",
    "        input_masks.append(input_mask)\n",
    "        segment_ids.append(segment_id)\n",
    "    return np.array(input_ids), np.array(input_masks), np.array(segment_ids)\n",
    "\n",
    "# Train the model\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "train_input = create_input_features\n",
    "(train, max_seq_length)\n",
    "val_input = create_input_features(val, max_seq_length)\n",
    "\n",
    "history = model.fit(\n",
    "train_input,\n",
    "train[\"label\"].values,\n",
    "validation_data=(val_input, val[\"label\"].values),\n",
    "batch_size=batch_size,\n",
    "epochs=epochs,\n",
    "verbose=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "plagiarism-checker-C_ALrIvo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
