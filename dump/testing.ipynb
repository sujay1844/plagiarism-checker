{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-04-01 11:38:31.503959: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import nltk\n",
    "nltk.data.path.append('/home/sujay1844/.local/share/nltk_data/')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import train_test_split\n",
    "# from nltk.stem.porter import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from sklearn.metrics import confusion_matrix, mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>The kids are frowning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
       "      <td>The boy skates down the sidewalk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2              Children smiling and waving at camera   \n",
       "3              Children smiling and waving at camera   \n",
       "4  A boy is jumping on skateboard in the middle o...   \n",
       "\n",
       "                                       sentence2  label  \n",
       "0  A person is at a diner, ordering an omelette.      0  \n",
       "1              A person is outdoors, on a horse.      1  \n",
       "2                     There are children present      1  \n",
       "3                          The kids are frowning      0  \n",
       "4              The boy skates down the sidewalk.      0  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\n",
    "\t'./train_snli.txt.zip',\n",
    "\tsep='\\t',\n",
    "\theader=None,\n",
    "\tnames=['sentence1', 'sentence2', 'label']\n",
    ")[:10_000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence1</th>\n",
       "      <th>sentence2</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is at a diner, ordering an omelette.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A person on a horse jumps over a broken down a...</td>\n",
       "      <td>A person is outdoors, on a horse.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>There are children present</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Children smiling and waving at camera</td>\n",
       "      <td>The kids are frowning</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A boy is jumping on skateboard in the middle o...</td>\n",
       "      <td>The boy skates down the sidewalk.</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           sentence1  \\\n",
       "0  A person on a horse jumps over a broken down a...   \n",
       "1  A person on a horse jumps over a broken down a...   \n",
       "2              Children smiling and waving at camera   \n",
       "3              Children smiling and waving at camera   \n",
       "4  A boy is jumping on skateboard in the middle o...   \n",
       "\n",
       "                                       sentence2  label  \n",
       "0  A person is at a diner, ordering an omelette.      0  \n",
       "1              A person is outdoors, on a horse.      1  \n",
       "2                     There are children present      1  \n",
       "3                          The kids are frowning      0  \n",
       "4              The boy skates down the sidewalk.      0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load the dataset\n",
    "df = pd.read_csv(\n",
    "\t'./train_snli.txt.zip',\n",
    "\tsep='\\t',\n",
    "\theader=None,\n",
    "\tnames=['sentence1', 'sentence2', 'label']\n",
    ")[:10_000]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))\n",
    "# stemmer = PorterStemmer()\n",
    "lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "def preprocess_text(text):\n",
    "\n",
    "    # Remove punctuations and digits\n",
    "    try:\n",
    "        text = re.sub('[^a-zA-Z\\s]', '', text)\n",
    "    except Exception as e:\n",
    "        print(\"Regex failed\", text)\n",
    "        print(e)\n",
    "        text = 'foo'\n",
    "\n",
    "    text = text.lower()\n",
    "\n",
    "    # Some sentences are empty after removing punctuations and digits, which causes errors\n",
    "    try:\n",
    "        words = nltk.word_tokenize(text)\n",
    "    except Exception as e:\n",
    "        print(\"Tokenization failed\", text)\n",
    "        print(e)\n",
    "        words = []\n",
    "\n",
    "    # Remove stop words and stem\n",
    "    # words = [stemmer.stem(word) for word in words if word not in stop_words]\n",
    "\n",
    "    # Remove stop words and lemmatize\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word not in stop_words]\n",
    "\n",
    "    # Join the words back into a sentence\n",
    "    text = ' '.join(words)\n",
    "    return text\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Apply the preprocess_text function to each sentence pair in the dataset\n",
    "df['sentence1'] = df['sentence1'].apply(preprocess_text)\n",
    "df['sentence2'] = df['sentence2'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vectorize the text data using Bag-of-Words (BoW)\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['sentence1'] + df['sentence2']).toarray()\n",
    "y = tf.keras.utils.to_categorical(df['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-24 14:31:48.571174: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2 AVX AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-03-24 14:31:48.647217: I tensorflow/core/common_runtime/process_util.cc:146] Creating new thread pool with default inter op setting: 2. Tune using inter_op_parallelism_threads for best performance.\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(128, activation='relu'),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "250/250 [==============================] - 8s 29ms/step - loss: 0.6926 - accuracy: 0.5080 - val_loss: 0.6900 - val_accuracy: 0.5005\n",
      "Epoch 2/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.6253 - accuracy: 0.6553 - val_loss: 0.7451 - val_accuracy: 0.4835\n",
      "Epoch 3/10\n",
      "250/250 [==============================] - 5s 21ms/step - loss: 0.4670 - accuracy: 0.7779 - val_loss: 1.0330 - val_accuracy: 0.4675\n",
      "Epoch 4/10\n",
      "250/250 [==============================] - 6s 22ms/step - loss: 0.2899 - accuracy: 0.8771 - val_loss: 1.4047 - val_accuracy: 0.4630\n",
      "Epoch 5/10\n",
      "250/250 [==============================] - 6s 24ms/step - loss: 0.1668 - accuracy: 0.9284 - val_loss: 1.8484 - val_accuracy: 0.4750\n",
      "Epoch 6/10\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 0.1042 - accuracy: 0.9563 - val_loss: 2.1388 - val_accuracy: 0.4625\n",
      "Epoch 7/10\n",
      "250/250 [==============================] - 7s 27ms/step - loss: 0.0735 - accuracy: 0.9712 - val_loss: 2.3240 - val_accuracy: 0.4710\n",
      "Epoch 8/10\n",
      "250/250 [==============================] - 6s 25ms/step - loss: 0.0512 - accuracy: 0.9806 - val_loss: 2.6211 - val_accuracy: 0.4730\n",
      "Epoch 9/10\n",
      "250/250 [==============================] - 6s 23ms/step - loss: 0.0355 - accuracy: 0.9843 - val_loss: 2.7993 - val_accuracy: 0.4805\n",
      "Epoch 10/10\n",
      "250/250 [==============================] - 5s 20ms/step - loss: 0.0298 - accuracy: 0.9883 - val_loss: 2.8386 - val_accuracy: 0.4740\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fc8a6a8d660>"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    batch_size=32,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model\n",
    "import pickle\n",
    "# pickle.dump(model, open('model.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "ReadError",
     "evalue": "file could not be opened successfully:\n- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('invalid header')",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mReadError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/home/sujay1844/drive/Projects/plagiarism-checker/testing.ipynb Cell 11\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/sujay1844/drive/Projects/plagiarism-checker/testing.ipynb#X12sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Load the model\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/sujay1844/drive/Projects/plagiarism-checker/testing.ipynb#X12sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m model \u001b[39m=\u001b[39m pickle\u001b[39m.\u001b[39;49mload(\u001b[39mopen\u001b[39;49m(\u001b[39m'\u001b[39;49m\u001b[39m./plagiarism-checker-50k.pkl\u001b[39;49m\u001b[39m'\u001b[39;49m, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m))\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.10/site-packages/keras/saving/pickle_utils.py:39\u001b[0m, in \u001b[0;36mdeserialize_model_from_bytecode\u001b[0;34m(serialized_model)\u001b[0m\n\u001b[1;32m     37\u001b[0m temp_dir \u001b[39m=\u001b[39m \u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mram://\u001b[39m\u001b[39m{\u001b[39;00muuid\u001b[39m.\u001b[39muuid4()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m\n\u001b[1;32m     38\u001b[0m b \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(serialized_model)\n\u001b[0;32m---> 39\u001b[0m \u001b[39mwith\u001b[39;00m tarfile\u001b[39m.\u001b[39;49mopen(fileobj\u001b[39m=\u001b[39;49mb, mode\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mr\u001b[39;49m\u001b[39m\"\u001b[39;49m) \u001b[39mas\u001b[39;00m archive:\n\u001b[1;32m     40\u001b[0m     \u001b[39mfor\u001b[39;00m name \u001b[39min\u001b[39;00m archive\u001b[39m.\u001b[39mgetnames():\n\u001b[1;32m     41\u001b[0m         dest_path \u001b[39m=\u001b[39m tf\u001b[39m.\u001b[39mio\u001b[39m.\u001b[39mgfile\u001b[39m.\u001b[39mjoin(temp_dir, name)\n",
      "File \u001b[0;32m~/.conda/envs/ml/lib/python3.10/tarfile.py:1639\u001b[0m, in \u001b[0;36mTarFile.open\u001b[0;34m(cls, name, mode, fileobj, bufsize, **kwargs)\u001b[0m\n\u001b[1;32m   1637\u001b[0m             \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m   1638\u001b[0m     error_msgs_summary \u001b[39m=\u001b[39m \u001b[39m'\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mjoin(error_msgs)\n\u001b[0;32m-> 1639\u001b[0m     \u001b[39mraise\u001b[39;00m ReadError(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mfile could not be opened successfully:\u001b[39m\u001b[39m\\n\u001b[39;00m\u001b[39m{\u001b[39;00merror_msgs_summary\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1641\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m \u001b[39min\u001b[39;00m mode:\n\u001b[1;32m   1642\u001b[0m     filemode, comptype \u001b[39m=\u001b[39m mode\u001b[39m.\u001b[39msplit(\u001b[39m\"\u001b[39m\u001b[39m:\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m1\u001b[39m)\n",
      "\u001b[0;31mReadError\u001b[0m: file could not be opened successfully:\n- method gz: ReadError('not a gzip file')\n- method bz2: ReadError('not a bzip2 file')\n- method xz: ReadError('not an lzma file')\n- method tar: ReadError('invalid header')"
     ]
    }
   ],
   "source": [
    "# Load the model\n",
    "model = pickle.load(open('./plagiarism-checker-50k.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 30ms/step\n",
      "('normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like', 'normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like')\n",
      "[2.1033704e-09 1.0000000e+00]\n",
      "1/1 [==============================] - 0s 55ms/step\n",
      "('normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like', 'scientist say success enterprise come community willingness defend assumption necessary considerable cost')\n",
      "[2.9003066e-05 9.9997103e-01]\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "('normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like', 'normal science often suppresses fundamental novelty necessarily subversive basic commitment')\n",
      "[2.9595711e-04 9.9970406e-01]\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "('much success enterprise derives community willingness defend assumption necessary considerable cost', 'normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like')\n",
      "[0.07797755 0.9220224 ]\n",
      "1/1 [==============================] - 0s 58ms/step\n",
      "('much success enterprise derives community willingness defend assumption necessary considerable cost', 'scientist say success enterprise come community willingness defend assumption necessary considerable cost')\n",
      "[0.87957686 0.12042319]\n",
      "1/1 [==============================] - 0s 50ms/step\n",
      "('much success enterprise derives community willingness defend assumption necessary considerable cost', 'normal science often suppresses fundamental novelty necessarily subversive basic commitment')\n",
      "[0.9976732  0.00232675]\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "('normal science example often suppresses fundamental novelty necessarily subversive basic commitment', 'normal science activity scientist inevitably spend almost time predicated assumption scientific community know world like')\n",
      "[5.9150927e-05 9.9994087e-01]\n",
      "1/1 [==============================] - 0s 67ms/step\n",
      "('normal science example often suppresses fundamental novelty necessarily subversive basic commitment', 'scientist say success enterprise come community willingness defend assumption necessary considerable cost')\n",
      "[0.16220011 0.8377999 ]\n",
      "1/1 [==============================] - 0s 34ms/step\n",
      "('normal science example often suppresses fundamental novelty necessarily subversive basic commitment', 'normal science often suppresses fundamental novelty necessarily subversive basic commitment')\n",
      "[0.66329014 0.3367098 ]\n"
     ]
    }
   ],
   "source": [
    "# test with own data\n",
    "para1 = \"Normal science, the activity in which most scientists inevitably spend almost all their time, is predicated on the assumption that the scientific community knows what the world is like. Much of the success of the enterprise derives from the community's willingness to defend that assumption, if necessary at considerable cost. Normal science, for example, often suppresses fundamental novelties because they are necessarily subversive of its basic commitments\"\n",
    "para2 = \"Normal science, the activity in which most scientists inevitably spend almost all their time, is predicated on the assumption that the scientific community knows what the world is like. Some scientists say that the success of the enterprise comes from the communityâ€™s willingness to defend that assumption, if necessary at considerable cost. Normal science often suppresses fundamental novelties because they are necessarily subversive of its basic commitments.\"\n",
    "\n",
    "para1 = nltk.sent_tokenize(para1)\n",
    "para2 = nltk.sent_tokenize(para2)\n",
    "preds = []\n",
    "for sent1 in para1:\n",
    "\tsingle_pred = []\n",
    "\tsent1 = preprocess_text(sent1)\n",
    "\tfor sent2 in para2:\n",
    "\t\tsent2 = preprocess_text(sent2)\n",
    "\t\tX_test = vectorizer.transform([sent1 + sent2]).toarray()\n",
    "\t\ty_pred = model.predict(X_test)\n",
    "\t\tprint((sent1, sent2))\n",
    "\t\tprint(y_pred[0])\n",
    "\t\tsingle_pred.append(y_pred[0])\n",
    "\t# print(single_pred)\n",
    "\tpreds.append(single_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[array([1.2329283e-06, 9.9999881e-01], dtype=float32), array([0.03193902, 0.96806103], dtype=float32), array([0.20104283, 0.7989572 ], dtype=float32)], [array([0.00524586, 0.9947542 ], dtype=float32), array([0.5131527 , 0.48684728], dtype=float32), array([0.9760982 , 0.02390184], dtype=float32)], [array([0.06701543, 0.9329846 ], dtype=float32), array([0.95893884, 0.04106119], dtype=float32), array([0.99461776, 0.0053823 ], dtype=float32)]]\n"
     ]
    }
   ],
   "source": [
    "print(preds)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following numbers are average of three runs with a dataset of 10,000 pairs of sentences.\n",
    "\n",
    "| Model | Accuracy |\n",
    "|--|--|\n",
    "| Base | 0.9872 |\n",
    "| Stemmed | 0.9866 |\n",
    "| Lemmetized | 0.9882 |"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "483c1676b37f8d4930ed37ec1ba56f4db158e67cf5cc60a5bba9f19e5aa8cc92"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
